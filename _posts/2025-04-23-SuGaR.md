---
title: "SuGaR"
date: 2025-04-23 
categories: [Study, Paper Review]
tags: [3d gaussian splatting, 3d representation, mesh]  # TAG names should always be lowercase
description: Surface-Aligned Gaussian Spatting for Efficient 3D Mesh Reconstruction and High-Quality Mesh-Rendering  

math: true
---

## SuGaR: [Surface-Aligned Gaussian Spatting for Efficient 3D Mesh Reconstruction and High-Quality Mesh-Rendering](https://arxiv.org/abs/2311.12775)
기존 Gaussian Splatting은 사실적인 뷰 합성에는 뛰어나지만 Gaussian들이 정렬되지 않아 mesh로의 변환이 어렵다는 한계를 갖는다. 본 논문은 3D Gaussian Splatting으로부터 빠르고 고품질의 Mesh를 추출하는 방법인 SuGaR를 제안한다. 

> SuGaR는 3D Gaussian Splatting으로부터 빠르고 정확하게 editable한 mesh를 추출하고, 이를 기반으로 고품질 렌더링과 직관적인 3D 장면 편집을 가능하게 하는 방법론을 제시한다.\
> _We propose a method to allow precise and extremely fast mesh extraction from 3D Gaussian Splatting - SuGaR 2024, CVPR_
{: .prompt-info }

## Intro
NeRF 이후 3D 장면의 새로운 시점을 합성하는 방식으로 **3D Gaussian Splatting**이 빠르게 주목받고 있다. 3DGS는 수백만 개의 3D Gaussian에 대해 위치, 회전, 색상, alpha blending 계수를 최적화하여 사실적인 이미지를 빠르게 생성할 수 있고 기존 NeRF에 비해 훈련 및 렌더링 속도가 빠르다는 장점이 있다.

그러나 3D Gaussian Splatting으로부터 **Scene의 Surface를 명확히 추출**하는 것은 여전히 어려운 문제다. 

- Gaussian들이 일반적으로 **불규칙하게 분포**되어 있으며
- **표면에 정렬되지 않고**, **구조적인 형태를 띠지 않기 때문**이다.

또한 대부분의 3D 그래픽 툴은 **Mesh 기반**으로 작동한다. 따라서 여러 파이프라인에서는 Mesh를 이용한 3D Representation을 적용하지만 **Gaussian 기반 표현에서 Mesh를 추출하는 작업은 한계가 존재한다.**

> DreamGaussian 에서도 3D Gaussian에서 Mesh를 추출하기는 하지만, marching cube 알고리즘을 사용한다. 이 방식으로 생성된 Mesh는 불규칙하고 coarse 한 표면을 갖는다.
> 반면 SuGaR에서는 Gaussian을 표면에 정렬시키는 정규화 기법을 도입함으로써, 구조적으로 정돈되고 추후 편집 및 렌더링에 용이한 Mesh를 추출한다.
> **SuGaR는 Gaussian이 표면에 정렬되도록 유도하는 Regularization Term을 도입하고, 이후 Mesh를 효율적으로 추출 및 최적화하는 파이프라인을 제안한다.**
{: .prompt-info }

본 논문에서 저자들이 주장하는 메인 contribution은 다음과 같다. 

**Step 1: Surface-Aligned Regularization**\
  → 납작하고 표면에 밀착된 이상적인 Gaussian을 가정하고,
  → 실제 Gaussian으로부터 계산된 밀도 함수가 이 이상적인 밀도 함수와 유사해지도록 정규화 항을 설계한다.

**Step 2: Efficient Mesh Extraction**\
  → Gaussian의 Depth Map을 활용하여 시각적으로 보이는 영역의 밀도 level set을 효율적으로 샘플링하고,
  → 이를 기반으로 Poisson Reconstruction을 적용하여 고품질 Mesh를 수 분 내에 생성한다.

**Step 3: Joint Refinement with Bound Gaussians**\
  → 추출된 Mesh에 Gaussian을 바인딩하고,
  → Gaussian과 Mesh를 함께 최적화(jointly optimize)하여 렌더링 품질을 높이고, 직관적인 3D 편집을 가능하게 한다.

## Methods 
본 논문에서는 Gaussian Splatting을 최적화하는 과정에서 Gaussian들이 표면(Surface)에 정렬되도록 하는 정규화 항(Regularization Term)을 추가적으로 도입한다. 이를 통해:

1. **Gaussian들이 표면 근처에서 균일하게 분포**되도록 하고,
2. 정렬된 Gaussian들로부터 **짧은 시간 내에 Mesh를 추출하는 기법**을 제안하며,
3. Mesh와 Gaussian을 바인딩한 후 **공동 최적화(Joint Optimization)를 수행**하는 Optional Refinement Strategy를 소개한다.

이제 Gaussian을 Surface에 정렬하는 과정(Aligning the Gaussians with the Surface)을  자세히 알아보자.

### Aligning the Gaussians with the Surface 
Gaussian Splatting을 기반으로 Mesh를 생성하려면 Gaussian들이 표면 근처에서 정렬된 상태여야 한다. 하지만 초기 Gaussian들은 표면과 무관하게 배치되므로, Gaussian들을 Surface에 맞게 배치하는 정규화 항을 도입하여 최적화해야 한다.

먼저, Gaussian을 표면에 정렬하기 위해 이상적인 상황을 가정하자.

> **ASSUMPTION**\
> ***“서로 겹치는 부분이 적고, 얇은(Flat) 모양을 가지는 Gaussian들이 표면 근처에 균등하게 분포한다.”*** (즉, Gaussian들이 넓게 분산되지 않고, 표면을 따라 균일하게 정렬되며, 서로 중복되는 부분이 거의 없는 상태를 이상적인 형태로 설정한다. 물론 이 경우는 매우 드문 경우일 것이다.)

접근 방법은 이상적인 가정에서 SDF(signed Distance Function)을 얻고, 실제 가우시안에서 얻은 SDF와 이상적인 SDF의 차이를 줄이는 방식으로 Gaussian을 최적화한다[^1].

⇒ 즉, **이상적인 분포(표면에 고루 분포)가 되도록 Gaussian들을 유도**한다.

#### Implementation Details
Gaussian Scene에서 Surface에 가까운 특정 점 𝑝 의 밀도를 정의한다. 식(1)

$$
d(p) = \sum_{g} \alpha_g \exp\left( -\frac{1}{2}(p - \mu_g)^T \Sigma_g^{-1}(p - \mu_g) \right)
$$
_식(1)_

- $α_g$  : Gaussian의 Alpha Blending 값 (opacity)
    - 특정 Gaussian이 전체 장면에 기여하는 정도를 나타낸다.
- Exponent 항 : 특정 Gaussian g가 점 p에서 얼마나 강항 영향을 미치는지 결정,
    - [Mahalanobis Distance](https://velog.io/@so_yeong/%EB%A7%88%ED%95%A0%EB%9D%BC%EB%85%B8%EB%B9%84%EC%8A%A4-%EA%B1%B0%EB%A6%ACMahalanobis-Distance%EC%9D%98-%EC%A7%81%EA%B4%80%EC%A0%81-%EC%9D%B4%ED%95%B4%EC%99%80-%EC%88%98%EC%8B%9D%EC%A0%81-%EC%9D%B4%ED%95%B4)
를 사용하여 점 p가 Gaussian 의 중심에 가까울수록 높은 값을 갖도록 설정한다.
    - 즉, 단순한 (유클리디안) 거리가 아닌 Gaussian 의 공분산(모양, 크기)까지 고려한 거리라고 이해하면 된다.
    - 단순히 점 p에 가까운 Gaussian을 택하는 것이 아닌, **Gaussian의 모양과 Opacity를 모두 고려해서, 특정 점을 표현할때 Gaussian들의 확률적인 기여정도를 반영한 값을 밀도 함수로 사용**한다.

앞서 언급한 **이상적인 가정**에서는 표면에 가까운 점 𝑝 에 대해서 표면을 나타내는 가우시안들이 겹치지 않게 하나씩 밖에 없다고 가정한다. 따라서 **특정 점 𝑝 에서 밀도는 그 점과 *공간적으로 가장 가까운* Gaussian 하나에 의해 결정될 가능성이 높다**. 마할라노비스 거리가 가장 작은 Gaussian을 Closest Gaussian, $g^*$ 으로 정의한다. 식(2)

$$
\alpha_{g^*} \exp\left( -\frac{1}{2}(p - \mu_{g^*})^T \Sigma_{g^*}^{-1}(p - \mu_{g^*}) \right)
$$
_식(2)_

![surface_aligned](/assets/img/sugar/surface_aligned.png){: width="500" height="300"}
_표면에 분포하는 이상적인 Gaussian 예시_

이상적인 Gaussian 배치에서는 마할라노비스 거리가 가장 가까운 Gaussian 하나만이 주요한 기여를 한다고 가정할 수 있으므로 특정 점 𝑝에서의 밀도 값은 가장 가까운 Gaussian $g^*$ 의 값으로 근사할 수 있다. 식(3)\
즉,여러개가 아닌 하나의 대표 가우시안 값만 사용한다.

$$ 
g^* = \arg\min_{g} \left\{ (p - \mu_g)^T \Sigma_g^{-1}(p - \mu_g) \right\}
$$
_식(3)_



또한, **이상적인 가우시안은 표면에서 납작하길 원한다**. 결과적으로  x, y, z 세 축의 Scaling Factor 중 한 값은 0에 가까워 질 것이다.

![flat_gaussian](/assets/img/sugar/flat_gaussian.png){: width="500" height="300"}
_이상적인 납작한 Gaussian 예시_

이때, 공분산을 고려하는 마할라노비스 거리는…

- 분산이 큰 경우(넓게 분포된 경우): 그 방향으로의 거리는 덜 중요하게 반영되지만
- 분산이 작은 경우(좁게 분포된 경우): 그 방향으로의 거리는 매우 민감하게 반영된다.

따라서 만약 가우시안들이 납작하게 표면에 붙어 있다면, **표면의 법선 방향의 거리는 표면 내 방향의 거리보다 훨씬 민감하게 반영**된다. 이 점을 고려하면 식(3)은 식(4)와 같이 근사될 수 있다.

$$
(p - \mu_g)^T \Sigma_g^{-1}(p - \mu_g) \approx \frac{1}{s_g^2} \langle p - \mu_g, n_g \rangle^2
$$
_식(4)_

> [증명]
> 
> ![pf1](/assets/img/sugar/pf1.png){: width="500" height="300"}
> ![pf2](/assets/img/sugar/pf2.png){: width="500" height="300"}

마지막으로, 우리가 Gaussian 으로 표현하고자 하는 것은 “Surface”이다. 즉 기존 가우시안에서 Alpha Blending 을 통해 여러 중첩된 Gaussian들의 투명도를 고려한 것과 달리, **표면에서는 보이거나, 안보이거나 둘 중 한 가지**이다. 이때 보이지 않는 투명한(Alpha Blending 값이 0인) Gaussian은 렌더링 과정에서 무시할 수 있기 때문에 우리는 Gaussian들의 Alpha Blending 값이 1이 되기를 원한다. $\alpha_g=1$


따라서 정리하자면 ***“서로 겹치는 부분이 적고, 얇은(Flat) 모양을 가지는 Gaussian들이 표면 근처에 균등하게 분포한다”*** 라는 이상적인 가정으로부터 우리는 특정 점 p에서 Gaussian의 Density 값을 최종적으로 아래와 같은 식으로 근사할 수 있다. 식(5)

$$
\bar{d}(p) = \exp\left( -\frac{1}{2s_{g^*}^2} \langle p - \mu_{g^*}, n_{g^*} \rangle^2 \right)
$$
_식(5)_

이제 위 Density Function에서 얻은 Density 값을 기준으로 $|d(p)-\bar{d}(p)|$ 항을 Optimization Loss에 더해 Gaussian들이 표면에 잘 정렬되도록 유도한다. 이 방법 역시 어느 정도 잘 동작하긴 하지만, 저자들은 Density 보다 **SDF를 이용한 Loss를 계산하는 것이 Gaussian의 정렬을 더 잘 유도**한다는 사실을 발견했다고 한다.
> 밀도를 이용해서 Level Set를 정의하려고 하지만, 이상적인 납작한 가우시안의 경우, [Level Set](https://deep-learning-study.tistory.com/648)가 의미가 없어진다.
> 결국 목적은 이상적인 Gaussian들의 분포로 이루어진 “표면”을 찾는 것이 목표이지만, Gaussian들은 분산을 가지는 Volumetric 한 표현이므로, 어느 한점이 표면이다라고 명확히 정의하기 어려움..
> → 그래서 밀도 함수를 도입해서 이상적인 밀도 함수의 값을 Level Set로 가지는 점들의 집합을 표면으로 간접적으로나마 추론하겠다는 건가??
> → 그런데 막상 그렇게 하려다보니, 이상적인 납작한 가우시안들은 Level Set를 나누는게 의미가 없어짐… 그래서 SDF 도입

따라서 거리를 이용해 직관적으로 표현하고자 밀도함수 식을 약간 수정한 [SDF](https://jjuke-brain.tistory.com/entry/Signed-Distance-Function-SDF)를 도입한다.\
밀도를 이용해 SDF로 표현한 이상적인 Distance Function의 식은 식(6)과 같다. 

$$
\bar{f}(p) = \pm s_{g^*} \sqrt{-2 \log\left( \bar{d}(p) \right)}
$$
_식(6)_

> [증명]
> 
> ![pf3](/assets/img/sugar/pf3.png){: width="500" height="300"}

SDF는 어떤 구역 안에 있으면 (-) 부호를, 밖에 있으면 (+) 부호를 갖고, 그 경계에 있는 경우 0의 값을 갖는다. SDF의 값이 0인 경우의 p위치를 특별히 그 경계, 즉 Surface라고 볼 수 있다. 즉 이상적인 밀도 $\bar{d}(p)$를 갖는경우이다. 식(7)

$$
f(p) = \pm s_{g^*} \sqrt{-2 \log\left( d(p) \right)}
$$
_식(7)_

$f(p)$를 그림으로 그려보면 아래 그래프와 유사한 모양이 되는데

![logx_graph](/assets/img/sugar/logx_graph.png)

- 밀도가 작아지면 값이 커지고 → 표면에서 멀어짐
- 밀도가 1이면 → 표면이기 때문에 SDF 값이 0 이 된다.


따라서 최종적인 Regularization Term은 $f(p)$를 이용해서 식(8) 처럼 나타낼 수 있다.

> SDF를 사용해서 표현한 최종적인 Regularization Term $R$ : Gaussian의 정렬을 유도한다.
> 
> $$
> \mathcal{R} = \frac{1}{|\mathcal{P}|} \sum_{p \in \mathcal{P}} \left| \hat{f}(p) - f(p) \right|
> $$
> _식(8)_
{: .prompt-info }

- $p$ : 샘플링한 3차원 point
    - 이때 샘플링하는 점 p는 식(9)의 분포를 따른다.
      $$
      p \sim \prod_{g} \mathcal{N}(\cdot; \mu_g, \Sigma_g)
      $$
      _식(9)_
- $f(p)$ : 점 p에서의 이상적인 SDF
- $\hat{f}(p)$  :  점 p에서 실제로 예측한 SDF

$R$의 목적은 $\hat{f}(p)≈f(p)$ 이 되도록 하는 것이다. 하지만 여기서 또 문제가 생긴다. Gaussian Splatting에서 직접적으로 SDF를 구하기는 어렵고, 모든 3차원 공간의 점 p에 대해 직접 계산하는 것은 비효율적이다.따라서 **본 논문에서는 Depth Map을 도입하여 $\hat{f}(p)$를 근사적으로 계산**한다. 

Depth Map은 카메라 시점에서 보이는 모든 픽셀에 대해 "해당 픽셀까지의 거리"를 z값(depth)으로 저장한 2D 이미지이다. Gaussian Splatting 에서 빠른 렌더링 속도를 위해 적용하는 Rasterizer를 확장 적용하여 Depth Map을 빠르게 구할 수 있다고 한다. 

$\hat{f}(p)≈depth (p)-DepthMapValue(p)$

(논문에 정확히 언급된 부분이 없어서 내가 이해한 내용을 그림으로 그려봤다.)

![dpethmap](/assets/img/sugar/dpethmap.png){: width="400" height="300"} 

![dpethmap_ori](/assets/img/sugar/dpethmap_ori.png){: width="300" height="300"} 

또한 추가적으로 $R_{Norm}$ 정규화 항은 SDF의 gradient 방향이 Gaussian의 법선 방향과 유사해지도록 유도함으로써, 표면의 기하학적 정렬뿐만 아니라 방향성까지도 일관성 있게 유지되도록 돕는다. 식(10)

> Gaussian의 방향을 맞춰주는 Regularzation Term
> 
> $$
> \mathcal{R}_{\text{Norm}} = \frac{1}{|\mathcal{P}|} \sum_{p \in \mathcal{P}} \left\| \frac{\nabla f(p)}{\| \nabla f(p) \|_2} - n_{g^*} \right\|_2^2
> $$
> _식(10)_

| 정규화 항 | 역할 | 유도 |
| --- | --- | --- |
| $R$ | 위치 정렬 | Gaussian 들이 표면에 **위치**하도록 |
| $R_{Norm}$ | 방향 정렬 | Gaussian의 **얇은 방향(법선)이 표면의 법선과 같도록** |


### Efficient Mesh Extraction
위의 두 정규화항을 통해서 Gaussian들을 표면에 정렬(식8)하고 납작한 방향이 표면과 일치하도록(식10) 만들었다. 이제 이 Gaussian들에서 Mesh를 추출해야 한다. 

Gaussian 의 **밀도를 기반으로 얻은 Level Set에서 3D points 들을 추출**하고, 그 **포인트들에 대해 Poisson Reconstruction을 적용하여 Mesh를 추출**한다. 이때 좋은 Quality를 위해 Points들에 SDF의 방향 성분까지 추가한다.

본 논문에서는 Gaussian Splatting에서 Mesh를 빠르게 추출하기 위한 핵심 단계로 **Level Set 위의 Point Sampling**을 제안한다. 이때의 주요 도전과제는 “**어떤 점이 표면에 해당하는가?**”를 효율적으로 판단하는 것이다. 우리는 특정 Lambda 값을 가지는 Level set을 표면으로 가정한다.

#### 1. Depth Map 기반 Sampling 
먼저, 시점(viewpoint)마다 렌더링된 **Depth Map**을 이용한다. 각 시점에서 랜덤한 픽셀 `m`을 선택하고, 그 픽셀을 지나는 **line-of-sight** 방향 벡터 `v`를 따라 3D 공간 상에서 `n`개의 점을 다음과 같이 샘플링한다.

$$
p_i = p + t_i \cdot v \quad (t_i \in [-3\sigma, 3\sigma])
$$

![sampling](/assets/img/sugar/sampling.png)
_line of sight에서 점을 샘플링한다_

#### 2. 밀도 함수 기반 Level Set 위치 추정
각 샘플링된 점 $p_i$에 대해, 앞서 정의된 Gaussian 기반의 밀도 함수 $d(p)$를 계산한다. 이제, 연속된 두 점 $(p_i, p_{i+1})$ 사이에서 밀도 값이 다음 조건을 만족한다면:

$$
d(p_i) < \lambda < d(p_{i+1})
$$

이 두 점 사이 어딘가에 밀도값이 $\lambda$인 지점이 존재함을 의미한다. 이 점을 Level Set 상의 점  $ p^* $ 이라 부르며 선형보간법으로 정확한 위치를 추정할 수 있다. 따라서 $d(p+t^*v)=d(p^*)=\lambda$를 만족하는 점을 찾을 수 있고 여러 개의 점들 중, 카메라와 가장 가까운 위치에 있는 점을 시각적으로 보이는 표면이라고 근사할 수 있게 된다. 

#### 3. Normal 계산 및 Mesh 재구성
이렇게 찾은 점 **$p^*$** 에서는 동시에 **SDF의 Gradient**를 이용해 Normal 벡터도 계산하고 **Poisson Surface Reconstruction 기법**을 통해 최종 Mesh를 생성한다.

![results1](/assets/img/sugar/results1.png)
_surface aligned 가우시안에서 추출한 점으로 렌더링한 결과(우)_

### Binding New 3D Gaussians to the Mesh
![triangle_coordinate](/assets/img/sugar/triangle_coordinate.png

SuGaR의 마지막 단계는 추출된 Triangle Mesh 위에 새로운 Gaussian을 바인딩(binding)하고 이를 다시 Gaussian Splatting Rasterizer로 최적화(Optimize)하는 과정이다. 이 과정은 Optional 하지만 해당 과정을 통해 표면을 더 정제하고 이후 3D 편집, Deformation, Animation 등 다양한 3D 툴에서 활용 가능한 표현력을 가질 수 있다고 한다. 

새로운 Gaussian 들은 [Barycentrical Coordiate, 질량 중심 좌표](https://xoft.tistory.com/60)에 각 Mesh의 사이즈에 따라 추가된다. 

![results2](/assets/img/sugar/results2.png)
_추가적인 Guassian Binding의 결과(하)_

이를 위해서 기존 3D GS에서 학습 가능한 파라미터들이 약간 바뀌게 된다. 

- Gaussian 들의 중심은 Optimize 단계에서 위의 질량중심 좌표계로 고정된다.
- Scaling Factor는 한 Factor가 0에 가까워지기 때문에 3개에서 2개로 줄어들고
- 회전을 정의하는 Quaternion도 여기서는 하나의 복소수로 표현된다.
    - 각 Gaussian들은 Mesh 삼각형의 **로컬 좌표계 위에 정의**되며, 평면 상의 회전 및 스케일 정보는 복소수로 표현되어 **효율적인 최적화와 견고한 편집을 가능하게 한다**.
- Opacity Value와 Spherical Harmonics는 기존 3D GS와 동일하게 설계된다.

![binding_gaussian](/assets/img/sugar/binding_gaussian.png)
_추가적인 Guassian Binding_

## Evaluation
![evaluation](/assets/img/sugar/evaluation.png)

Mip-NeRF360 데이터 셋에 대해 실험한 결과이다. 

- Mesh 적용 전에는 3DGS 보다 낮은 성능을 가지지만
- Mesh 적용 후에는 Mesh화 하는 다른 연구들 중 가장 높은 성능을 보인다.

### Ablation Studies
![ablation](/assets/img/sugar/ablation.png){: width="500" height="300"}

Mesh를 추출하는 다른 기법들을 적용해본 Ablation study이다. 
- Marching Cube 알고리즘을 적용한 경우
- Poisson Reconstruction 시 샘플링되는 점을 Gaussian의 중점으로 사용할 경우
- Surface Density Level을 0.1~0.5로 했을 경우

Surface Level을 0.5로 한 경우 가장 높은 성능을 보인다(근데 논문에서는 0.3을 쓴다고 한다, 왜..?)

![ablation1](/assets/img/sugar/ablation1.png){: width="500" height="300"}

Mesh의 Triangle 개수에 따른 Quality 실험이다. 

- 전통적인 UV Texture 방식을 적용한 실험은 Vertex 개수를 늘리면 성능이 주는 반면
- 본 연구에서 제시한 3DGS에서 추출한 Mesh의 Vetex 개수를 늘리면 성능이 높아진다.
- 특히 더 많은 1M vertices를 사용한 UV방식보다, 3DGS 방식에서 더 적은 200k의 vertices를 사용해도 성능이 더 높다.


![ablation2](/assets/img/sugar/ablation2.png)

[^1]: [SDF 설명 블로그](https://jjuke-brain.tistory.com/entry/Signed-Distance-Function-SDF#google_vignette)

